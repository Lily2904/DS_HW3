{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lilit_Kalantar_HW3_Problem1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc4Y_P253dnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#installing scrapy\n",
        "!pip install scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIeduahqC67V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time \n",
        "import requests\n",
        "from scrapy.http import TextResponse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw5ChfOgDFhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url=\"http://books.toscrape.com/\"\n",
        "base_url = \"http://books.toscrape.com/catalogue/\"\n",
        "base_url1 = \"http://books.toscrape.com/\"\n",
        "page = requests.get(url)\n",
        "response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6TeGKyzRpKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separately defining scraping functions for book title, rating, price, hyperlink, picture, availability, individual page, genre and description\n",
        "\n",
        "def get_title(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  title = response.css(\"a[title]::attr(title)\").extract()\n",
        "  return title\n",
        "  \n",
        "def get_rating(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  rating =response.css(\"p[class^='star-rating']::attr(class)\").extract()\n",
        "  return rating \n",
        "\n",
        "def get_price(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  price = response.xpath(\"//p[@class = 'price_color']/text()\").extract()\n",
        "  price = [i.replace(\"Â£\", \" \") for i in price]\n",
        "  return price\n",
        "\n",
        "def get_hyperlink(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  hyperlink = [base_url +i for i in response.css(\"a[title]::attr(href)\").extract()]\n",
        "  return hyperlink\n",
        "\n",
        "def get_book_picture(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  book_picture_url = response.css(\"img::attr(src)\").extract()\n",
        "  book_picture = [base_url1 +i for i in book_picture_url]\n",
        "  return book_picture\n",
        "\n",
        "def get_availabilities(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  availability = response.xpath(\"//p[contains(@class,'stock')]/text()[2]\").re(\"\\w+.+\\w\")\n",
        "  return availability\n",
        "\n",
        "def individual_page_url(url):\n",
        "    page = requests.get(url)\n",
        "    response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "    individual_page = [base_url+'catalogue/'+i for i in response.xpath('//article[@class=\"product_pod\"]//div[@class = \"image_container\"]/a/@href').extract()]\n",
        "    return individual_page\n",
        "\n",
        "def book_genre(url): \n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  genre = response.xpath(\"//ul[@class = 'breadcrumb']/li[3]/a/text()\").extract_first()\n",
        "  return genre\n",
        "\n",
        "def book_description(url):\n",
        "    page = requests.get(url)\n",
        "    response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "    description = response.xpath(\"//article[@class='product_page']/p/text() \").extract_first()\n",
        "    return description\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9FJ1KWIBY6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the links for all pages for using them while scraping all pages of the website\n",
        "#The range is from 1 to 51, since we have 50 pages\n",
        "all_pages = [base_url+\"catalogue/page-{}.html\".format(i) for i in range(1,51)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb3b4601BaCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining empty lists for each item, and extending the scraped first page to the rest of the pages\n",
        "#Items below are present on all pages of the website, therefore they can be extended together \n",
        "all_titles = []\n",
        "all_ratings = []\n",
        "all_prices = []\n",
        "all_hyperlinks = []\n",
        "all_book_pictures = []\n",
        "all_availabilities = []\n",
        "individual_page = []\n",
        "for i in all_pages:\n",
        "    all_titles.extend(get_title(i))\n",
        "    all_ratings.extend(get_rating(i))\n",
        "    all_prices.extend(get_price(i))\n",
        "    all_hyperlinks.extend(get_hyperlink(i))\n",
        "    all_book_pictures.extend(get_book_picture(i))\n",
        "    all_availabilities.extend(get_availabilities(i))\n",
        "    individual_page.extend(individual_page_url(i))\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCMNHVBGNfAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating empty lists for genre and descriptions in a similar manner and appending them to the individual page, \n",
        "#as they are a part of all pages\n",
        "books_genre = []\n",
        "books_descriptions = []\n",
        "for i in individual_page:\n",
        "    books_genre.append(book_genre(i))\n",
        "    books_descriptions.append(book_description(i))\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVJh9eXQbLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining all the separate lists aand turning the into one DataFrame\n",
        "df = pd.DataFrame(np.column_stack([all_titles, all_ratings, all_prices, all_hyperlinks, all_book_pictures, all_availabilities, individual_page, books_genre, books_descriptions]), columns = ['Titles', 'Ratings', 'Prices', 'Hyperlinks', 'Book_Pictures', 'Availabilities', 'Individual_Page', 'Books_Genre', 'Books_Descriptions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggyPbSbNRdRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting DataFrame into a csv file\n",
        " df.to_csv('books.csv', index=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjK5mssMRh7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading the new csv file to perform analysis \n",
        "data = pd.read_csv(\"books.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fei7-YGURmG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f280fe2e-76e5-46b4-aa3a-dfe4c62719e8"
      },
      "source": [
        "# 1. The follwing code calculates the average price for all books\n",
        "data[\"Prices\"].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.07034999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuNw9pwMRvOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b194e2c7-b7f2-4aa7-a8a0-2f59812e0e51"
      },
      "source": [
        "# 2. The following code identifies the most expensive genre by first grouping prices by genre, then calculating mean prices,\n",
        "#sorting values in the descending order, and leaving only the most expensive one\n",
        "data['Prices'].groupby(data['Books_Genre']).mean().sort_values(ascending = False).head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Books_Genre\n",
              "Suspense    58.33\n",
              "Name: Prices, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KdDf5n0VZCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3.1 Replacing the string values of the Rating column by numeric values to further use them in calculations\n",
        "data.Ratings[data.Ratings == 'star-rating One'] = 1\n",
        " data.Ratings[data.Ratings == 'star-rating Two'] = 2\n",
        "data.Ratings[data.Ratings == 'star-rating Three'] = 3\n",
        "data.Ratings[data.Ratings == 'star-rating Four'] = 4\n",
        "data.Ratings[data.Ratings == 'star-rating Five'] = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcZC-cXnUTBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e53d8d3-8c86-4c10-9937-06bca54033cd"
      },
      "source": [
        "# 3.2 Correlation coefficient determines the relationship between two numeric variables. In this case, we can say that we have a weak positive relationship\n",
        "#which is not enough to state that books with higher prices do have higher ratings. \n",
        "# Additionally, correlation does not show causality, and we cannot say that one factor causes the other.\n",
        "data[\"Prices\"].corr(data[\"Ratings\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.028166239485873015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    }
  ]
}